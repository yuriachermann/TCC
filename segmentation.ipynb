{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Notebook for Tool Segmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T16:21:15.917425600Z",
     "start_time": "2023-09-07T16:21:15.836676400Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.pyplot'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtransforms\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcv2\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib.pyplot'"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.transforms.v2.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import src.data_utils as data_utils\n",
    "import src.plot_utils as plot_utils\n",
    "from src.ToolSegmentationDataset import Toolhead_Dataset\n",
    "from src.Trainer import Trainer\n",
    "from src.loss_functions import Dice_Segmentation_Loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Collect Data and create dataset (train and validation dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.863534600Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.865528200Z"
    }
   },
   "outputs": [],
   "source": [
    "# collect data from path\n",
    "train_path = \"./data/train\"\n",
    "valid_path = \"./data/validation\"\n",
    "\n",
    "# scrap the full path string\n",
    "train_img_path, train_annot_path = data_utils.collectDatasetImages(train_path)\n",
    "valid_img_path, valid_annot_path = data_utils.collectDatasetImages(valid_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Augment dataset using torchvision transforms v2 for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.867521200Z"
    }
   },
   "outputs": [],
   "source": [
    "img_resolution = [512, 512]\n",
    "\n",
    "train_augmentations = transforms.Compose([\n",
    "    transforms.Resize(img_resolution, antialias=False),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "])\n",
    "\n",
    "valid_augmentations = transforms.Compose([\n",
    "    transforms.Resize(img_resolution, antialias=False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.868517900Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Toolhead_Dataset(train_img_path, train_annot_path, train_augmentations)\n",
    "valid_dataset = Toolhead_Dataset(valid_img_path, valid_annot_path, valid_augmentations)\n",
    "\n",
    "b_size = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=b_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=b_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model and Training:\n",
    "- Initialize necessary model and parameters\n",
    "- Initialize the Trainer and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.869514200Z"
    }
   },
   "outputs": [],
   "source": [
    "unet = smp.Unet(\n",
    "    encoder_name='resnet34', \n",
    "    encoder_depth=4, \n",
    "    encoder_weights='imagenet', \n",
    "    decoder_use_batchnorm=True, \n",
    "    decoder_channels=(128, 64, 32, 16), \n",
    "    decoder_attention_type=None, \n",
    "    in_channels=3, \n",
    "    classes=1, \n",
    "    activation=None, \n",
    "    aux_params=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.871507400Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr)\n",
    "dice_loss = Dice_Segmentation_Loss()\n",
    "label_counts = 2\n",
    "\n",
    "segmentation_trainer = Trainer(\n",
    "    model=unet, \n",
    "    optimizer=optimizer, \n",
    "    criterion=dice_loss,\n",
    "    train_loader=train_loader, \n",
    "    valid_loader=valid_loader, \n",
    "    label_counts=label_counts,\n",
    "    epochs=50, \n",
    "    print_intermediate_vals=True, \n",
    "    gradient_accumulation=1,\n",
    "    save_model_on_every_epoch=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Load prior trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.872503700Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model_path = \"./saved_model/epoch_49.pth\"\n",
    "segmentation_trainer.load_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.874509500Z"
    }
   },
   "outputs": [],
   "source": [
    "# segmentation_trainer.train_model()                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save Values and evaluate - Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.876494100Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = segmentation_trainer.train_loss\n",
    "val_loss = segmentation_trainer.val_loss\n",
    "loss_iters = segmentation_trainer.loss_iters\n",
    "valid_mIoU = segmentation_trainer.valid_mIoU\n",
    "valid_mAcc = segmentation_trainer.valid_mAcc\n",
    "conf_mat = segmentation_trainer.conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.877487200Z"
    }
   },
   "outputs": [],
   "source": [
    "_, loss_ax = plot_utils.plot_results(train_loss, val_loss, [\"Train Loss\", \"Validation Loss\"])\n",
    "_, measure_ax = plot_utils.plot_results(valid_mIoU, valid_mAcc, [\"IoU\", \"Acc\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save and/or Plot Segmentation masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Train img Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.881473700Z"
    }
   },
   "outputs": [],
   "source": [
    "# plots\n",
    "_, ax = plt.subplots(len(train_dataset), 5, figsize=(20,12))\n",
    "\n",
    "for i, (img, gt_segmentation) in enumerate(train_dataset):\n",
    "    \n",
    "    img = img.unsqueeze(0).to(device)\n",
    "\n",
    "    preds = segmentation_trainer.model(img)\n",
    "    # prediction to one hot encoding\n",
    "    one_hot = torch.sigmoid(preds)\n",
    "    one_hot[one_hot >= 0.5] = 1\n",
    "    one_hot[one_hot < 0.5] = 0\n",
    "\n",
    "    one_hot = one_hot.squeeze(0).detach().cpu().numpy().transpose(1, 2, 0)\n",
    "    img = img.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "    gt_segmentation = gt_segmentation.numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    vb_img = plot_utils.segment_mask_as_overlay(img, one_hot, color=\"red\")\n",
    "    vb_gt = plot_utils.segment_mask_as_overlay(img, gt_segmentation, color=\"blue\")\n",
    "\n",
    "    ax[i][0].grid(False)\n",
    "    ax[i][0].set_title(\"Original Image\")\n",
    "    ax[i][1].grid(False)\n",
    "    ax[i][1].set_title(\"GT Segmentation Mask\")\n",
    "    ax[i][2].grid(False)\n",
    "    ax[i][2].set_title(\"GT Segmentation Overlay\")\n",
    "    ax[i][3].grid(False)\n",
    "    ax[i][3].set_title(\"Predicted Segmentation Mask\")\n",
    "    ax[i][4].grid(False)\n",
    "    ax[i][4].set_title(\"Predicted Segmentation Overlay\")\n",
    "    ax[i][0].imshow(img)\n",
    "    ax[i][1].imshow(gt_segmentation)\n",
    "    ax[i][2].imshow(vb_gt)\n",
    "    ax[i][3].imshow(one_hot)\n",
    "    ax[i][4].imshow(vb_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Test img Plot. Optional: Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-07T16:21:15.883478600Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = \"./data/test/\"\n",
    "test_img_paths = data_utils.collectImagePaths(test_path)\n",
    "\n",
    "save = True\n",
    "save_folder = \"./data/segmented_imgs/\"\n",
    "os.makedirs(os.path.dirname(save_folder), exist_ok=True)\n",
    "\n",
    "# plots\n",
    "_, ax = plt.subplots(len(test_img_paths), 3, figsize=(15,8))\n",
    "\n",
    "for i, path in enumerate(test_img_paths):\n",
    "    # load image\n",
    "    img = Image.open(path)\n",
    "    # convert PIL to Tensor\n",
    "    img = F.pil_to_tensor(img)\n",
    "\n",
    "    # process image:\n",
    "    img = F.resize(img, img_resolution, antialias=True)\n",
    "    img = img / img.max()\n",
    "    img = img.float().to(device)\n",
    "\n",
    "    if len(img.shape) == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    preds = segmentation_trainer.model(img)\n",
    "    # prediction to one hot encoding\n",
    "    one_hot = torch.sigmoid(preds)\n",
    "    one_hot[one_hot >= 0.5] = 1\n",
    "    one_hot[one_hot < 0.5] = 0\n",
    "\n",
    "    one_hot = one_hot.squeeze(0).detach().cpu().numpy().transpose(1, 2, 0)\n",
    "    img = img.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    vb_img = plot_utils.segment_mask_as_overlay(img, one_hot, color=\"red\")\n",
    "\n",
    "    ax[i][0].grid(False)\n",
    "    ax[i][0].set_title(\"Original Image\")\n",
    "    ax[i][1].grid(False)\n",
    "    ax[i][1].set_title(\"Predicted Segmentation Mask\")\n",
    "    ax[i][2].grid(False)\n",
    "    ax[i][2].set_title(\"Segmentation Overlay\")\n",
    "    ax[i][0].imshow(img)\n",
    "    ax[i][1].imshow(one_hot)\n",
    "    ax[i][2].imshow(vb_img)\n",
    "\n",
    "    if save == True:\n",
    "        file_name = os.path.basename(path)\n",
    "        name_without_extension = os.path.splitext(file_name)[0]\n",
    "        # for cv2 it wants values between 0 and 255 and BGR Channels instead of RGB\n",
    "        cv2.imwrite(save_folder + name_without_extension + \"_segmented.jpg\", vb_img[:, :, ::-1] * 255)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-ede0f17bb58ffa398fac1d7143e4bacfbf09eb40",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
